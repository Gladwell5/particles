{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/pid_train.csv', low_memory=False)\n",
    "df_test = pd.read_csv('../data/pid_test.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look a the first few rows\n",
    "print(df_train.head())\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting models requires us to split datasets into what we want to use as predictors and what we want to predict\n",
    "predictor_variables = ['p', 'theta', 'beta', 'nphe', 'ein', 'eout']\n",
    "outcome_variable = 'id'\n",
    "\n",
    "# The variables we want to use in prediction are conventionally named X\n",
    "X_train = df_train[predictor_variables]\n",
    "X_test = df_test[predictor_variables]\n",
    "\n",
    "# The outcome categories should be sequential integers (0, 1, 2, etc.)\n",
    "# So we'll order the unique set of particle ids/types alphabetically...\n",
    "outcome_values = sorted(list(set(df_train['id'])))\n",
    "\n",
    "# ...and then use that to create the outcome vectors (conventionally named y)\n",
    "y_train = [outcome_values.index(_id) for _id in df_train[outcome_variable]]\n",
    "y_test = [outcome_values.index(_id) for _id in df_test[outcome_variable]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_train is still a dataframe so you can use .head() to look at the first 5 rows\n",
    "print(X_train.head())\n",
    "print(X_train.describe())\n",
    "\n",
    "# y_train is a vector so you can use [i:j] syntax to look at the first 5 values\n",
    "print(y_train[:5])\n",
    "print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And the same for test\n",
    "print(X_test.head())\n",
    "print(X_test.describe())\n",
    "print(y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can fit the multinomial logistic regression model and print the results on the test set\n",
    "model = LogisticRegression(random_state=1234, max_iter=100, verbose=0)\n",
    "model.fit(X_train, y_train)\n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And the same with a random forest classifier\n",
    "classifier = RandomForestClassifier(n_estimators=10, random_state=1234, verbose=1)\n",
    "classifier.fit(X_train, y_train)\n",
    "print(classification_report(y_test, classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do experimentation by varying\n",
    "#   a) the scaled/unscaled variables\n",
    "#   b) the balanced/unbalanced training set\n",
    "#   c) the unbalanced training set but setting the class_weight argument of the models to 'balanced'\n",
    "#   d) other model parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
