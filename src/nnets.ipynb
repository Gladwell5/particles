{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "\n",
    "from nn_helpers import ParticleDS, train_loop, test_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A neural net is a sequence of layers with different numbers of parameters\n",
    "# This one has 4 layers\n",
    "# - an input linear layer with 6 inputs (the number of predictor variables) and 16 outputs (this is arbitrary)\n",
    "# - an Rectified Linear Unit layer which adjusts the results of the first layer to be 0 below 0\n",
    "# - a second linear layer with 16 inputs and 4 outputs (the number of particle types)\n",
    "# - a final layer that gets the most likely output of the 4 previous output values to give a final prediction\n",
    "class TinyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(in_features=6, out_features=8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=8, out_features=4),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "nn_model = TinyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data in using our custom dataset classes (which is defined in the helpers file)\n",
    "batch_size = 32\n",
    "predictors = ['p', 'theta', 'beta', 'nphe', 'ein', 'eout']\n",
    "#predictors = ['p_scaled', 'theta_scaled', 'beta_scaled', 'nphe_scaled', 'ein_scaled', 'eout_scaled']\n",
    "outcome = 'id'\n",
    "\n",
    "train_ds = ParticleDS('../data/pid_train_balanced.csv', predictors, outcome)\n",
    "test_ds = ParticleDS('../data/pid_test.csv', predictors, outcome)\n",
    "\n",
    "print(Counter(train_ds.y))\n",
    "print(Counter(test_ds.y))\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are just typical values that tend to work as a first pass\n",
    "# Experimenting with these to get the best model is called hyperparameter tuning\n",
    "learning_rate = .1\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "# Cross Entropy Loss is a popular way to measure the difference between predicted categories and actual categories (aka loss)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# Stochastic Gradient Descent is the method that updates the model parameters (aka how it learns)\n",
    "optimiser = torch.optim.SGD(nn_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# The train loop and test loop are defined in our nn_helpers file - have a look at those to see what's happening in each loop\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, nn_model, loss_fn, optimiser, batch_size)\n",
    "    test_loop(test_dataloader, nn_model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the final performance metrics on the test set\n",
    "nn_model.eval()\n",
    "pred_y = torch.argmax(nn_model(test_ds.X), dim=1).detach().numpy()\n",
    "print(classification_report(test_ds.y, pred_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
